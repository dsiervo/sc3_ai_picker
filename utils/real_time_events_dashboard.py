#!/home/dsiervo/anaconda3/envs/streamlit/bin/python
# -*- coding: utf-8 -*-
"""
Created on Feb 19 2021

@author: Daniel Siervo, emetdan@gmail.com
"""

import streamlit as st
from streamlit_autorefresh import st_autorefresh
import mysql.connector
import pandas as pd
import numpy as np
import plotly.express as px
import pydeck as pdk
from streamlit.file_util import streamlit_write
from cmcrameri import cm
from matplotlib.colors import Normalize
import base64
import time
from datetime import datetime, timedelta


def load_and_dashboard(ti, min_lat, max_lat, min_lon, max_lon):
    """Create streamlit dashboard where to explore the data
    from a seismic catalog in XML SC3 format

    Parameters
    ----------
    xml_path : str
        SeisComP events xml like file path.
    """
    
    # SETTING PAGE CONFIG TO WIDE MODE
    st.set_page_config(layout="wide", page_icon='ðŸ”ž', page_title='Earthquake Explorer')
    st.title("Catalog Exploration (Montebello - Antioquia)")

    # update every 10 seconds
    st_autorefresh(interval= 5 * 60 * 1000, key="dataframerefresh")
    
    # get current date time in format YYYY-MM-DD hh:mm:ss
    now = datetime.now() + timedelta(hours=5)
    tf = now.strftime("%Y-%m-%d %H:%M:%S")
    # query events data
    csv_path = query_and_df(ti, tf, min_lat, max_lat, min_lon, max_lon)
    st.markdown(f"### Data showed from {ti} to {tf} UTC")

    print('\n\tCreando dashboard interactivo...')
    dashboard = Dashboard(csv_path, ti, tf)
    df = dashboard.load_data()
    print(df.info())
    dashboard.create_dashboard(df)


def query_and_df(ti, tf, min_lat, max_lat, min_lon, max_lon):
    mydb = mysql.connector.connect(host="172.25.3.135",
                                   user="consulta",
                                   passwd="consulta",
                                   database="seiscomp3")

    query_str = '''
    SELECT 
    POEv.publicID AS 'ID',
    DATE_FORMAT(Origin.time_value, '%Y/%m/%d %H:%i:%S') AS 'orig_time', 
    CASE
        WHEN AreaOfInfluence.area IS NOT NULL THEN AreaOfInfluence.latitude
        ELSE Origin.latitude_value
        END AS lat,
    CASE
        WHEN AreaOfInfluence.area IS NOT NULL THEN AreaOfInfluence.longitude
        ELSE Origin.longitude_value
        END AS lon,
    CASE
        WHEN AreaOfInfluence.area IS NOT NULL THEN ROUND(AreaOfInfluence.depth)
        ELSE ROUND(Origin.depth_value) 
        END AS z,
    CASE
        WHEN AreaOfInfluence.area IS NOT NULL THEN AreaOfInfluence.magnitude
        ELSE ROUND(Magnitude.magnitude_value, 1)
        END AS mag,
    Origin.creationInfo_author as 'author',
    Origin.quality_usedStationCount as 'stationcount',
    Origin.quality_usedPhaseCount as 'phasecount',
    Origin.latitude_uncertainty as 'lat_e',
    Origin.longitude_uncertainty as 'lon_e',
    Origin.depth_uncertainty as 'z_e',
    Origin.quality_minimumDistance as 'min_dis',
    Origin.quality_standardError as 'rms [s]',
    CASE
        WHEN AreaOfInfluence.area IS NOT NULL THEN AreaOfInfluence.area
        ELSE convert(cast(convert(EventDescription.text using latin1) as binary) using utf8)
        END AS 'region'
    FROM  
    Event AS EvMF left join PublicObject AS POEv ON EvMF._oid = POEv._oid
    left join AreaOfInfluence on AreaOfInfluence.publicId = POEv.publicID
    left join PublicObject as POOri ON EvMF.preferredOriginID=POOri.publicID 
    left join Origin ON POOri._oid=Origin._oid
    left join PublicObject as POMag on EvMF.preferredMagnitudeID=POMag.publicID  
    left join Magnitude ON Magnitude._oid = POMag._oid 
    left join EventDescription ON EvMF._oid=EventDescription._parent_oid  
    WHERE  
    Origin.time_value BETWEEN '{ti}' AND '{tf}' 
    AND Origin.latitude_value BETWEEN {min_lat} AND {max_lat} AND Origin.longitude_value BETWEEN {min_lon} AND {max_lon}

    # =====================================================
    # localizables (descomentar/comentar la siguiente lÃ­nea para solo localizables/no localizables
    # =====================================================
    AND (EvMF.type like 'earthquake' or EvMF.type is null or EvMF.type like 'volcanic eruption'or AreaOfInfluence.area is not null) AND Magnitude.magnitude_value IS NOT null AND Origin.latitude_uncertainty IS NOT NULL AND Origin.longitude_uncertainty IS NOT NULL AND Origin.quality_azimuthalGap IS NOT NULL 
    # =====================================================
    # no localizables
    # =====================================================
    #and (EvMF.type like 'not locatable' or EvMF.type like 'explosion' or EvMF.type like 'earthquake' or EvMF.type is null or EvMF.type like 'volcanic eruption' or AreaOfInfluence.area is not null) 

    ORDER BY Origin.time_value
    '''
    
    query = query_str.format(ti=ti, tf=tf,
                             min_lat=min_lat, max_lat=max_lat,
                             min_lon=min_lon, max_lon=max_lon)

    print(query)
    df = pd.read_sql(query, con=mydb)
    print(df.info())

    #writting the dataframe to a csv file
    #csv_path = 'events_data.csv'
    #df.to_csv('events_data.csv', index=False)
    return df


class Dashboard(object):
    def __init__(self, df, ti, tf):
        self.df = df
        self.ti = ti
        self.tf = tf

    #@st.cache(persist=True)
    def load_data(self):
        # Loading data as a pandas DataFrame retriving only the columns of our interest
        #df = pd.read_csv(self.csv_path, index_col=0, parse_dates=[6])
        df = self.df
        df.sort_values(by='mag', ascending=False, inplace=True)
        df['mag_scale'] = 800 * (4 ** df.mag)
        df.rename(columns={'z':'depth [km]', 'mag':'magnitude', 'lat':'latitude', 'lon':'longitude',
                'phasecount':'phase count', 'stationcount':'station count',
                'z_e':'depth error [km]', 'lat_e':'latitude error [km]',
                'lon_e':'longitude error [km]', 'orig_time': 'date',
                'min_dis':'minimum station distance [km]'}, inplace=True)
        df['date'] = df['date'].astype('datetime64[ns]')
        return df

    def get_table_download_link(self, df):
        """Generates a link allowing the data in a given panda dataframe to be downloaded
        in:  dataframe
        out: href string
        """
        csv = df.to_csv(index=False)
        b64 = base64.b64encode(csv.encode()).decode()  # some strings <-> bytes conversions necessary here
        href = f'<a href="data:file/csv;base64,{b64}" download="data.csv">Download csv file</a>'
        return href

    def create_dashboard(self, df):
        """Have the streamlit front code
        """

        """st.sidebar.header('Data filter')
        filter_type = st.sidebar.radio('Filter type', ('slider', 'number input'))
        #st.sidebar.subheader("Magnitude")
        if filter_type == 'slider':
            mag_range = st.sidebar.slider("Magnitude range", -1.0, 10.0, (0.0, 7.0), 0.1)
        else:
            st.sidebar.markdown("### Magnitude")
            min_mag = st.sidebar.number_input('Minimun magnitude', value=-1.0, step=0.1)
            max_mag = st.sidebar.number_input('Maximun magnitude', value=10.0, step=0.1)
            mag_range = (min_mag, max_mag)
        #st.sidebar.markdown(f"Magnitude range: {mag_range}")
        
        #st.sidebar.subheader("Latitude")
        lat_min, lat_max = float(df.latitude.min()), float(df.latitude.max())
        if filter_type == 'slider':
            lat_range = st.sidebar.slider("Latitude range", lat_min, lat_max, (lat_min, lat_max), 0.1)
        else:
            st.sidebar.markdown("### Latitude")
            min_lat = st.sidebar.number_input('Minimun latitude', value=lat_min, step=0.01)
            max_lat = st.sidebar.number_input('Maximun latitude', value=lat_max, step=0.01)
            lat_range = (min_lat, max_lat)

        lon_min, lon_max = float(df.longitude.min()), float(df.longitude.max())
        if filter_type == 'slider':
            lon_range = st.sidebar.slider("Longitude range", lon_min, lon_max, (lon_min, lon_max), 0.1)
        else:
            st.sidebar.markdown("### Longitude")
            min_lon = st.sidebar.number_input('Minimun Longitude', value=lon_min, step=0.01)
            max_lon = st.sidebar.number_input('Maximun Longitude', value=lon_max, step=0.01)
            lon_range = (min_lon, max_lon)

        depth_min, depth_max = float(df['depth [km]'].min()), float(df['depth [km]'].max())
        if filter_type == 'slider':
            depth_range = st.sidebar.slider("Depth range [km]", depth_min, depth_max, (depth_min, depth_max), 0.1)
        else:
            st.sidebar.markdown("### Depth")
            min_depth = st.sidebar.number_input('Minimun Depth', value=depth_min, step=0.01)
            max_depth = st.sidebar.number_input('Maximun Depth', value=depth_max, step=0.01)
            depth_range = (min_depth, max_depth)

        rms_min, rms_max = float(df['rms [s]'].min()), float(df['rms [s]'].max())
        if filter_type == 'slider':
            rms_range = st.sidebar.slider("RMS range [s]", rms_min, rms_max, (rms_min, rms_max), 0.1)
        else:
            st.sidebar.markdown("### RMS")
            min_rms = st.sidebar.number_input('Minimun RMS', value=rms_min, step=0.01)
            max_rms = st.sidebar.number_input('Maximun RMS', value=rms_max, step=0.01)
            rms_range = (min_rms, max_rms)

        min_date, max_date = df['date'].min().to_pydatetime(), df['date'].max().to_pydatetime()
        min_date, max_date = min_date.replace(hour=0, minute=0, second=0), max_date.replace(hour=23, minute=59, second=59)
        dt = timedelta(days=1)
        if filter_type == 'slider':
            date_min, date_max = st.sidebar.slider("Date range", df['date'].min(), df['date'].max(),
                                                   (min_date, max_date), dt)
            date_min, date_max = date_min - dt, date_max - dt
        else:
            st.sidebar.markdown("### Date")
            date_min, date_max = st.sidebar.date_input('Date range', [min_date, max_date],
                                                       min_value=df['date'].min(),
                                                       max_value=df['date'].max())
            
        query = f'latitude >= {lat_range[0]} and latitude < {lat_range[1]} \
                and longitude >= {lon_range[0]} and longitude < {lon_range[1]}\
                and magnitude >= {mag_range[0]} and magnitude < {mag_range[1]}\
                and `depth [km]` >= {depth_range[0]} and `depth [km]` < {depth_range[1]}\
                and `rms [s]` >= {rms_range[0]} and `rms [s]` < {rms_range[1]}\
                and date >= "{date_min}" and date < "{date_max}"'

        df = df.query(query)"""
        
        show_table = st.checkbox("Show raw data", True)
        if show_table:
            col_list = [col for col in df.columns.to_list() if col not in ['mag_scale',
                                                                           'author',
                                                                           'originID']]
            columns = st.multiselect(
                'Columns to show:',
                col_list,
                col_list
            )
            df.sort_values(by='date', ascending=False, inplace=True)
            styler = df[columns].style.format(
                        {
                            'date': lambda x: x.strftime("%d-%m-%Y %H:%M:%S")
                        }).set_table_styles('styles')
            st.dataframe(styler)
            downlad_link = self.get_table_download_link(df[columns])
            st.markdown(downlad_link, unsafe_allow_html=True)
        
        st.markdown(f"Selected earthquakes: **{len(df)}**.")
        
        st.header('Graphics')
        st.subheader('Number of Earthquakes by ...')
        col1, col2, col3 = st.beta_columns(3)
        for col, type_ in zip([col1, col2, col3],
                             ['magnitude', 'rms [s]', 'depth [km]']):
            with col:
                counts, bins = np.histogram(df[type_], bins=np.arange(int(df[type_].min()), int(df[type_].max()+1),0.5))
                bins = 0.5 * (bins[:-1] + bins[1:])
                fig = px.bar(x=bins, y=counts, labels={'x':type_, 'y':'Number of EQ'}, height=500)
                # Option-1:  using fig.update_yaxes()
                #fig.update_yaxes(visible=False, showticklabels=True)
                st.plotly_chart(fig, use_container_width=True)
        
        # date histogram
        colt1, colt2 = st.beta_columns(2)
        with colt1:
            trange = st.selectbox('Time range',
                                  ['days', 'weeks', 'months', 'years'])
        with colt2:
            pass

        y_name = f'Earthquakes by {trange}'
        count = df['date'].groupby([df['date'].dt.to_period(f'1{trange[0]}')]).count()
        count_df = pd.DataFrame({'date':count.index, y_name:count.values})
        count_df['date'] = count_df['date'].astype('str')
        fig = px.bar(count_df, x='date', y=y_name, height=600,
                     range_x=[self.ti, self.tf])
        st.plotly_chart(fig, use_container_width=True)

        st.header('Depth Profiles')
        cold1, cold2 = st.beta_columns(2)
        df['depth [km]'] = -1 * df['depth [km]']
        with cold1:
            fig = px.scatter(df, x="latitude", y="depth [km]", 
                            size='mag_scale', color="rms [s]", hover_name="date")
            st.plotly_chart(fig, use_container_width=True)
        with cold2:
            fig = px.scatter(df, x="longitude", y="depth [km]", 
                            size='mag_scale', color="rms [s]", hover_name="date")
            st.plotly_chart(fig, use_container_width=True)
        df['depth [km]'] = -1 * df['depth [km]']

        st.header('Map')
        colm1, colm2 = st.beta_columns(2)
        with colm1:
            style = st.selectbox('Style', ['outdoors-v11', 'streets-v11',
                                           'light-v9', 'light-v10',
                                           'dark-v10', 'satellite-v9',
                                           'satellite-streets-v11'])
            opacity = st.slider('Color opacity', 0.0, 1.0, value=0.6)
        with colm2:
            pass

        self.map(df, opacity, style)
    
    def map(self, data, opacity, style):
        # custom map
        cmap = cm.batlow_r
        data.sort_values(by='magnitude', ascending=False, inplace=True)
        # we need to normalize the depth in order to use
        # matplotlib cmap properly
        norm = Normalize(vmin=data['depth [km]'].min(), vmax=data['depth [km]'].max())
        data['norm'] = data['depth [km]'].apply(norm)

        def get_color(depth_norm):
            # cmap returns a tuple of normalized rgba elements
            # we desnormalize and keep with the first three (rgb)
            c = cmap(depth_norm)
            return [x*255 for x in c][:-1]

        data['color'] = data['norm'].apply(get_color)

        data['dates_str'] = data['date'].apply(lambda x: x.strftime('%Y-%m-%d %H:%M:%S'))
        data['magnitude'] = data['magnitude'].round(1)
        data['depth [km]'] = data['depth [km]'].round(1)
        data['latitude_str'] = data['latitude'].round(2)
        data['longitude_str'] = data['longitude'].round(2)

        layers = [
            pdk.Layer(
                'ScatterplotLayer',
                data=data,
                pickable=True,
                stroked=True,
                opacity=opacity,
                get_position='[longitude, latitude]',
                get_radius='mag_scale',
                get_fill_color='color',
                get_line_color=[0, 0, 0],
                line_width_min_pixels=0.3
            )
        ]

        r = pdk.Deck(
            tooltip={"text": "{latitude_str}, {longitude_str} \n {dates_str}\n Magnitude: {magnitude}\n Depth: {depth [km]} km"},
            map_style=f'mapbox://styles/mapbox/{style}',
            initial_view_state=pdk.ViewState(
                latitude=data['latitude'].median(),
                longitude=data['longitude'].median(),
                zoom=7,
                pitch=0,
            ),
            layers=layers
        )
        st.pydeck_chart(r, use_container_width=True)


if __name__ == '__main__':
    
    # streamlit run real_time_events_dashboard.py
    load_and_dashboard(min_lat=5.8, max_lat=6, min_lon=-75.8, max_lon=-75.3,
                    ti='2021-01-01 00:00:00')
        
